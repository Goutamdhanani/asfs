# ğŸ¬ Automated Short-Form Content Clipping & Distribution System

A **fully automated, production-ready system** that transforms long-form videos into viral-worthy short clips optimized for TikTok, Instagram Reels, and YouTube Shorts.

## ğŸ¯ Overview

This system intelligently:
- **Analyzes** long-form video content
- **Identifies** high-engagement, viral-potential segments
- **Extracts** platform-optimized short videos
- **Generates** captions and hashtags
- **Schedules** uploads with rate limiting
- **Publishes** to TikTok, Instagram Reels, and YouTube Shorts via official APIs

**This is a real production system** â€” fully implemented, no placeholders, no mock data.

## ğŸ—ï¸ Architecture

```
Input Video
    â†“
Audio Extraction (FFmpeg - fast)
    â†“
Transcript + Timestamps (Whisper)
    â†“
Transcript Quality Validation
    â†“
Candidate Segment Builder (Sentence + Pause Windows)
    â†“
AI Highlight Scoring (GitHub Models)
    â†“
Clip Validation & Deduplication
    â†“
FFmpeg Clip Extraction from Original Video + 9:16 Crop
    â†“
Metadata & Caption Generation
    â†“
Queue & Rate-Control Scheduler
    â†“
Official Platform Upload APIs
    â†“
Audit Logs & Retry System
```

## ğŸ“ Project Structure

```
asfs/
â”œâ”€â”€ ingest/              # Video normalization (not used in MVP)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ normalize.py     # FFmpeg video standardization
â”œâ”€â”€ transcript/          # Transcription & quality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transcribe.py    # Faster-Whisper transcription (multi-threaded)
â”‚   â”œâ”€â”€ audio_extract.py # Fast audio extraction
â”‚   â””â”€â”€ quality_check.py # Transcript validation
â”œâ”€â”€ segmenter/           # Candidate segment building
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentence_window.py  # Sentence-based windowing
â”‚   â””â”€â”€ pause_window.py     # Pause-based windowing
â”œâ”€â”€ ai/                  # AI highlight scoring
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scorer.py        # GitHub Models integration
â”‚   â””â”€â”€ prompt.txt       # Scoring prompt template
â”œâ”€â”€ cache/               # Pipeline state caching (NEW)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ checkpoint.py    # Resume from last completed stage
â”œâ”€â”€ validator/           # Clip validation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dedup.py         # Semantic deduplication
â”‚   â””â”€â”€ overlap.py       # Overlap removal
â”œâ”€â”€ clipper/             # Clip extraction
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ extract.py       # FFmpeg clip extraction
â”œâ”€â”€ metadata/            # Caption & hashtag generation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ captions.py      # Platform-specific captions
â”‚   â””â”€â”€ hashtags.py      # Hashtag strategies
â”œâ”€â”€ scheduler/           # Upload scheduling
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ queue.py         # Rate limiting & retry logic
â”œâ”€â”€ uploaders/           # Platform upload APIs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tiktok.py        # TikTok Content Posting API
â”‚   â”œâ”€â”€ instagram.py     # Instagram Graph API
â”‚   â””â”€â”€ youtube.py       # YouTube Data API v3
â”œâ”€â”€ audit/               # Logging & audit trail
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py        # SQLite audit logging
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ platforms.json   # Platform specifications
â”‚   â”œâ”€â”€ rate_limits.json # Upload rate limits
â”‚   â””â”€â”€ model.yaml       # AI model configuration
â”œâ”€â”€ main.py              # Main orchestrator
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ CACHE_FEATURE.md     # Caching documentation
â””â”€â”€ README.md           # This file
```

## ğŸš€ Quick Start

### Prerequisites

1. **FFmpeg** - Must be installed and available in PATH
   ```bash
   # Ubuntu/Debian
   sudo apt-get install ffmpeg
   
   # macOS
   brew install ffmpeg
   
   # Windows
   # Download from https://ffmpeg.org/download.html
   ```

2. **Python 3.8+**

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Aaryanrao0001/asfs.git
   cd asfs
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up API credentials** (see Configuration section)

### Configuration

#### Required Environment Variables

Create a `.env` file or set environment variables:

```bash
# GitHub Models (required for AI scoring)
export GITHUB_TOKEN="your_github_token"

# TikTok (optional - for uploads)
export TIKTOK_ACCESS_TOKEN="your_tiktok_token"

# Instagram (optional - for uploads)
export INSTAGRAM_ACCESS_TOKEN="your_instagram_token"
export INSTAGRAM_USER_ID="your_instagram_user_id"

# YouTube (optional - for uploads)
export YOUTUBE_CREDENTIALS_FILE="path/to/credentials.json"
export YOUTUBE_TOKEN_FILE="path/to/token.json"
```

#### GitHub Models Setup

1. Get a GitHub Personal Access Token from https://github.com/settings/tokens
2. Set `GITHUB_TOKEN` environment variable
3. The system uses GitHub Models (OpenAI-compatible API) for free

#### Local LLM Support (Optional)

The system now supports **local inference** using Ollama with automatic fallback to remote APIs.

**Quick Setup:**
1. Install Ollama: https://ollama.ai/download
2. Pull a supported model: `ollama pull qwen3:latest`
3. Install Python SDK: `pip install ollama`
4. Configure in `config/model.yaml`:
   ```yaml
   llm_backend: "auto"  # auto | local | api
   local_model_name: "qwen3:latest"  # or qwen3:8b, qwen3:14b
   ```

**Backend Modes:**
- `auto` (default): Try local â†’ fallback to API if unavailable
- `local`: Require local â†’ fallback to API with warning if unavailable
- `api`: Use API only, skip local

**Benefits:** No API costs, no rate limits, works offline, faster inference.

**Configuration Best Practices:**

Memory Management:
- Set `local_keep_alive: "5m"` in `config/model.yaml` to reduce model reload times
- Use `"10m"` or `"-1"` (indefinite) if processing many videos continuously
- Default is `"5m"` (5 minutes)

GPU Requirements:
- `qwen3:8b` requires ~6GB VRAM
- For GPUs with <6GB VRAM, use CPU mode: `OLLAMA_NO_GPU=1 ollama serve`
- Or use smaller models like `qwen3:4b`

Model Names:
- Use exact names from `ollama list`
- Example: `qwen3:8b` not `qwen3:latest` unless explicitly pulled with that tag
- The system will auto-detect and use the exact available model name

Troubleshooting:
- If you see "memory allocation" errors: Use CPU mode or smaller model
- If model not found: Run `ollama list` and update `local_model_name` in config
- Test inference is performed automatically to verify GPU/memory capability

#### Platform API Setup

**TikTok:**
1. Register at https://developers.tiktok.com/
2. Create an app and get OAuth2 credentials
3. Complete OAuth flow to get access token

**Instagram:**
1. Set up Facebook Developer account
2. Create an app with Instagram Graph API permissions
3. Get access token and user ID

**YouTube:**
1. Create project in Google Cloud Console
2. Enable YouTube Data API v3
3. Download OAuth2 credentials JSON
4. First run will open browser for authentication

### Usage

**Basic usage (with caching enabled by default):**
```bash
python main.py /path/to/video.mp4
```

**Custom output directory:**
```bash
python main.py /path/to/video.mp4 -o /path/to/output
```

**Verbose logging:**
```bash
python main.py /path/to/video.mp4 -v
```

**Disable caching (force full reprocessing):**
```bash
python main.py /path/to/video.mp4 --no-cache
```

### ğŸ”„ Pipeline Caching & Resume Feature

The pipeline **automatically caches** intermediate results and can **resume from the last completed stage** if interrupted or if processing the same video again.

**Benefits:**
- âš¡ **2-5 minute time savings** on re-runs
- ğŸ” Resume interrupted pipelines
- ğŸ§ª Perfect for testing configuration changes
- ğŸš€ Faster development iteration

**Cached Stages:**
- Audio Extraction (~10s â†’ <1s)
- Transcription (~60-120s â†’ <1s) 
- Segmentation (~5s â†’ <1s)
- AI Scoring (~60-300s â†’ <1s) â­ **Most valuable**

**Example when resuming:**
```
âœ“ Found cached state from 2024-02-07T02:30:45
âœ“ Last completed stage: ai_scoring

STAGE 1: AUDIO EXTRACTION
âœ“ SKIPPED (using cached result)
...
```

**Cache Management:**
```bash
# View cache files
ls -lh output/cache/

# Clear caches
rm -rf output/cache/
```

ğŸ“– See [CACHE_FEATURE.md](CACHE_FEATURE.md) for detailed documentation.

## ğŸ“Š Pipeline Stages

### 1. Video Normalization
- Normalizes codec to H.264
- Converts to 30fps
- Standardizes audio to AAC 44100Hz stereo
- Preserves original aspect ratio (no cropping)
- Ensures platform compatibility

**Note:** Aspect ratio conversion is deferred to clip extraction stage for better performance.

### 2. Transcript Generation
- Uses Faster-Whisper (4x faster than standard Whisper)
- Multi-threaded CPU inference with CTranslate2
- Voice Activity Detection (VAD) to skip silence
- Generates sentence-level timestamps
- Provides word-level timing data

### 3. Quality Validation
- Checks timestamp continuity
- Validates word density (words/second)
- Detects excessive filler words
- Confirms language confidence

**Pass criteria:** Overall quality score â‰¥ 0.6

### 4. Candidate Segmentation
- **Sentence windows:** 10-75 second overlapping windows
- **Pause windows:** Natural speech breaks
- Generates 50-200+ candidates per video

### 5. AI Highlight Scoring
- Uses GitHub Models (GPT-4) for analysis
- Evaluates:
  - Hook strength (first 2 seconds)
  - Emotional resonance
  - Clarity and completeness
  - Virality potential
  - Platform fit
- Generates captions and hashtags
- Recommends best platforms

**Threshold:** Only segments scoring â‰¥ 6.0/10 proceed

### 6. Validation & Deduplication
- **Overlap removal:** Eliminates time-overlapping clips
- **Semantic dedup:** Removes similar content (Jaccard similarity)
- Keeps highest-scoring clips

### 7. Clip Extraction
- FFmpeg-based precise extraction
- Re-encodes for platform compatibility
- Applies vertical format (1080x1920) to selected clips only
- Generates individual MP4 files

**Performance:** By cropping only selected clips (instead of the entire video during normalization), 
processing time is significantly reduced, especially for long videos.

### 8. Metadata Generation
- **Captions:** Platform-specific, with CTAs
- **Hashtags:** Mix of niche + broad tags
- **Filenames:** Structured clip IDs

### 9. Upload Scheduling
- Rate limiting per platform (default: 1/hour)
- Priority-based queue
- Exponential backoff retry logic
- Respects platform quotas

### 10. Platform Uploads
- **TikTok:** Content Posting API
- **Instagram:** Graph API (requires hosted video)
- **YouTube:** Data API v3 with OAuth2
- Comprehensive error handling
- Upload status tracking

### 11. Audit Logging
- SQLite database for all events
- Tracks pipeline stages
- Records upload attempts
- Supports failure recovery

## ğŸ“ Configuration Files

### `config/model.yaml`
```yaml
model:
  endpoint: "https://models.inference.ai.azure.com"
  model_name: "gpt-4o"
  temperature: 0.7
  max_tokens: 500
  max_segments_to_score: 50
  min_score_threshold: 6.0
```

### `config/platforms.json`
Platform specifications (duration limits, resolution, API endpoints)

### `config/rate_limits.json`
Upload frequency controls:
- Cooldown periods
- Daily/hourly limits
- Retry configurations

## ğŸ¥ Output

After running the pipeline, you'll find:

```
output/
â”œâ”€â”€ work/
â”‚   â”œâ”€â”€ audio.wav           # Extracted audio (for transcription)
â”‚   â””â”€â”€ transcript.json     # Full transcript with timestamps
â”œâ”€â”€ clips/
â”‚   â”œâ”€â”€ clip_001.mp4        # Extracted + cropped clip 1 (9:16)
â”‚   â”œâ”€â”€ clip_002.mp4        # Extracted + cropped clip 2 (9:16)
â”‚   â””â”€â”€ ...
â””â”€â”€ pipeline.log            # Detailed execution log

audit/
â””â”€â”€ events.db               # SQLite audit database
```

**Note:** No normalized video is created. Clips are extracted directly from the original video.

## ğŸ” Monitoring & Debugging

### View Pipeline Logs
```bash
tail -f pipeline.log
```

### Query Audit Database
```python
from audit import AuditLogger

audit = AuditLogger()

# Get upload history
uploads = audit.get_upload_history(platform="TikTok")

# Get pipeline summary
summary = audit.get_pipeline_summary()
```

### Common Issues

**No clips generated:**
- Check transcript quality score
- Lower `min_score_threshold` in config/model.yaml
- Verify video has clear speech

**Upload failures:**
- Verify API credentials are set
- Check rate limits in logs
- Review platform-specific errors

**FFmpeg errors:**
- Ensure FFmpeg is installed: `ffmpeg -version`
- Check video codec compatibility
- Review FFmpeg logs in pipeline.log

**Whisper errors:**
- May require GPU for large models
- Try smaller model: edit transcribe.py, use "tiny" or "base"
- Check available disk space

## ğŸ” Security & Privacy

- **No hardcoded credentials** - All secrets via environment variables
- **Official APIs only** - No browser automation or scraping
- **Local processing** - Videos stay on your machine
- **Audit trail** - Complete logging of all operations

## ğŸš¨ Rate Limits & Best Practices

### Default Rate Limits
- **TikTok:** 1 upload/hour, 10/day
- **Instagram:** 1 upload/hour, 10/day
- **YouTube:** 1 upload/hour, 10/day

### Recommendations
1. Start with conservative rate limits
2. Monitor platform responses
3. Adjust based on account status
4. Use test accounts initially

## ğŸ› ï¸ Development

### Adding New Platforms

1. Create uploader in `uploaders/new_platform.py`
2. Implement `upload_to_platform()` function
3. Add configuration to `config/platforms.json`
4. Add rate limits to `config/rate_limits.json`
5. Update `main.py` to include new platform

### Customizing AI Prompts

Edit `ai/prompt.txt` to adjust scoring criteria and output format.

### Extending Segmentation

Add new windowing strategies in `segmenter/` directory.

## ğŸ“„ License

This project is provided as-is for educational and commercial use.

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## âš ï¸ Disclaimer

- **Platform Policies:** Ensure compliance with TikTok, Instagram, and YouTube Terms of Service
- **Content Rights:** Only process videos you have rights to
- **Rate Limits:** Respect platform upload limits to avoid account restrictions
- **API Quotas:** Monitor your API usage and quotas

## ğŸ“ Support

For issues, questions, or feature requests, please open an issue on GitHub.

---

**Built with:** Python, FFmpeg, Faster-Whisper, GitHub Models, Platform APIs

**Status:** Production-ready, fully implemented, no placeholders