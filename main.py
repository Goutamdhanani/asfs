#!/usr/bin/env python3
"""
Automated Short-Form Content Clipping & Distribution System

Main orchestrator that runs the full pipeline:
1. Video ingest & normalization
2. Transcript generation
3. Transcript quality validation
4. Candidate segment building
5. AI highlight scoring
6. Clip validation & deduplication
7. FFmpeg clip extraction
8. Metadata generation
9. Scheduling & rate control
10. Platform uploads
11. Audit logging
"""

import os
import sys
import logging
import json
import yaml
import argparse
from pathlib import Path
from typing import Dict, List

# Import pipeline modules
from ingest import normalize_video
from transcript import transcribe_video, check_transcript_quality
from transcript.transcribe import load_transcript
from segmenter import build_sentence_windows, build_pause_windows
from ai import score_segments
from validator import deduplicate_clips, remove_overlapping_clips
from clipper import extract_clips
from metadata import generate_captions, generate_hashtags
from scheduler import UploadQueue
from scheduler.queue import load_rate_limits
from uploaders import upload_to_tiktok, upload_to_instagram, upload_to_youtube
from audit import AuditLogger


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)


def load_config() -> Dict:
    """Load configuration from files."""
    config = {}
    
    # Load model config
    model_config_path = "config/model.yaml"
    if os.path.exists(model_config_path):
        with open(model_config_path, 'r') as f:
            config['model'] = yaml.safe_load(f)['model']
    else:
        logger.warning(f"Model config not found: {model_config_path}")
        config['model'] = {
            'endpoint': 'https://models.inference.ai.azure.com',
            'model_name': 'gpt-4o',
            'temperature': 0.7,
            'max_tokens': 500
        }
    
    # Load platform config
    platforms_config_path = "config/platforms.json"
    if os.path.exists(platforms_config_path):
        with open(platforms_config_path, 'r') as f:
            config['platforms'] = json.load(f)
    else:
        logger.warning(f"Platforms config not found: {platforms_config_path}")
        config['platforms'] = {}
    
    # Load rate limits
    rate_limits_path = "config/rate_limits.json"
    config['rate_limits'] = load_rate_limits(rate_limits_path)
    
    return config


def run_pipeline(video_path: str, output_dir: str = "output"):
    """
    Run the complete pipeline.
    
    Args:
        video_path: Path to input video
        output_dir: Directory for output files
    """
    logger.info("=" * 80)
    logger.info("AUTOMATED SHORT-FORM CONTENT CLIPPING PIPELINE")
    logger.info("=" * 80)
    
    # Verify input video exists
    if not os.path.exists(video_path):
        logger.error(f"Input video not found: {video_path}")
        sys.exit(1)
    
    # Load configuration
    logger.info("Loading configuration...")
    config = load_config()
    
    # Initialize audit logger
    audit = AuditLogger()
    audit.log_pipeline_event("initialization", "started", video_path)
    
    # Create output directories
    work_dir = os.path.join(output_dir, "work")
    clips_dir = os.path.join(output_dir, "clips")
    os.makedirs(work_dir, exist_ok=True)
    os.makedirs(clips_dir, exist_ok=True)
    
    try:
        # Stage 1: Video Normalization
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 1: VIDEO NORMALIZATION")
        logger.info("=" * 80)
        audit.log_pipeline_event("normalization", "started", video_path)
        
        try:
            normalized_video = normalize_video(video_path, work_dir)
            logger.info(f"✓ Normalized video: {normalized_video}")
            audit.log_pipeline_event("normalization", "completed", video_path, 
                                    {"output": normalized_video})
        except Exception as e:
            logger.error(f"✗ Normalization failed: {str(e)}")
            audit.log_pipeline_event("normalization", "failed", video_path, 
                                    error_message=str(e))
            raise
        
        # Stage 2: Transcript Generation
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 2: TRANSCRIPT GENERATION")
        logger.info("=" * 80)
        audit.log_pipeline_event("transcription", "started", video_path)
        
        try:
            transcript_path = transcribe_video(normalized_video, work_dir)
            logger.info(f"✓ Transcript saved: {transcript_path}")
            
            transcript_data = load_transcript(transcript_path)
            audit.log_pipeline_event("transcription", "completed", video_path,
                                    {"segments": len(transcript_data.get("segments", []))})
        except Exception as e:
            logger.error(f"✗ Transcription failed: {str(e)}")
            audit.log_pipeline_event("transcription", "failed", video_path,
                                    error_message=str(e))
            raise
        
        # Stage 3: Transcript Quality Check
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 3: TRANSCRIPT QUALITY VALIDATION")
        logger.info("=" * 80)
        audit.log_pipeline_event("quality_check", "started", video_path)
        
        try:
            quality_score, passed, quality_metrics = check_transcript_quality(transcript_data)
            
            logger.info(f"✓ Quality Score: {quality_score:.2f}/1.0")
            logger.info(f"✓ Quality Check: {'PASSED' if passed else 'FAILED'}")
            
            if not passed:
                logger.warning("Transcript quality is below threshold")
                logger.warning("Proceeding with caution - results may be suboptimal")
            
            audit.log_pipeline_event("quality_check", "completed", video_path,
                                    {"score": quality_score, "passed": passed})
        except Exception as e:
            logger.error(f"✗ Quality check failed: {str(e)}")
            audit.log_pipeline_event("quality_check", "failed", video_path,
                                    error_message=str(e))
            raise
        
        # Stage 4: Candidate Segment Building
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 4: CANDIDATE SEGMENT BUILDING")
        logger.info("=" * 80)
        audit.log_pipeline_event("segmentation", "started", video_path)
        
        try:
            # Build sentence-based windows
            sentence_candidates = build_sentence_windows(transcript_data)
            logger.info(f"✓ Sentence-based candidates: {len(sentence_candidates)}")
            
            # Build pause-based windows
            pause_candidates = build_pause_windows(transcript_data)
            logger.info(f"✓ Pause-based candidates: {len(pause_candidates)}")
            
            # Combine candidates
            all_candidates = sentence_candidates + pause_candidates
            logger.info(f"✓ Total candidates: {len(all_candidates)}")
            
            audit.log_pipeline_event("segmentation", "completed", video_path,
                                    {"total_candidates": len(all_candidates)})
        except Exception as e:
            logger.error(f"✗ Segmentation failed: {str(e)}")
            audit.log_pipeline_event("segmentation", "failed", video_path,
                                    error_message=str(e))
            raise
        
        if not all_candidates:
            logger.error("No candidate segments generated")
            audit.log_pipeline_event("pipeline", "failed", video_path,
                                    error_message="No candidate segments")
            return
        
        # Stage 5: AI Highlight Scoring
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 5: AI HIGHLIGHT SCORING")
        logger.info("=" * 80)
        audit.log_pipeline_event("ai_scoring", "started", video_path)
        
        try:
            scored_segments = score_segments(all_candidates, config['model'])
            logger.info(f"✓ Scored segments: {len(scored_segments)}")
            
            # Filter by minimum score threshold
            min_score = config['model'].get('min_score_threshold', 6.0)
            high_quality_segments = [
                seg for seg in scored_segments 
                if seg.get('overall_score', 0) >= min_score
            ]
            
            logger.info(f"✓ High-quality segments (score >= {min_score}): {len(high_quality_segments)}")
            
            audit.log_pipeline_event("ai_scoring", "completed", video_path,
                                    {"scored": len(scored_segments),
                                     "high_quality": len(high_quality_segments)})
        except Exception as e:
            logger.error(f"✗ AI scoring failed: {str(e)}")
            audit.log_pipeline_event("ai_scoring", "failed", video_path,
                                    error_message=str(e))
            raise
        
        if not high_quality_segments:
            logger.warning("No high-quality segments found")
            logger.info("Try lowering the min_score_threshold in config/model.yaml")
            audit.log_pipeline_event("pipeline", "completed", video_path,
                                    {"clips": 0, "reason": "No high-quality segments"})
            return
        
        # Stage 6: Clip Validation & Deduplication
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 6: CLIP VALIDATION & DEDUPLICATION")
        logger.info("=" * 80)
        audit.log_pipeline_event("validation", "started", video_path)
        
        try:
            # Remove overlapping clips
            non_overlapping = remove_overlapping_clips(high_quality_segments)
            logger.info(f"✓ Non-overlapping clips: {len(non_overlapping)}")
            
            # Deduplicate
            unique_clips = deduplicate_clips(non_overlapping)
            logger.info(f"✓ Unique clips: {len(unique_clips)}")
            
            audit.log_pipeline_event("validation", "completed", video_path,
                                    {"validated_clips": len(unique_clips)})
        except Exception as e:
            logger.error(f"✗ Validation failed: {str(e)}")
            audit.log_pipeline_event("validation", "failed", video_path,
                                    error_message=str(e))
            raise
        
        if not unique_clips:
            logger.warning("No clips remaining after validation")
            return
        
        # Stage 7: Clip Extraction
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 7: CLIP EXTRACTION")
        logger.info("=" * 80)
        audit.log_pipeline_event("extraction", "started", video_path)
        
        try:
            extracted_clips = extract_clips(normalized_video, unique_clips, clips_dir)
            logger.info(f"✓ Extracted clips: {len(extracted_clips)}")
            
            # Log each clip
            for clip in extracted_clips:
                audit.log_clip(clip)
            
            audit.log_pipeline_event("extraction", "completed", video_path,
                                    {"extracted": len(extracted_clips)})
        except Exception as e:
            logger.error(f"✗ Extraction failed: {str(e)}")
            audit.log_pipeline_event("extraction", "failed", video_path,
                                    error_message=str(e))
            raise
        
        if not extracted_clips:
            logger.error("No clips were extracted")
            return
        
        # Stage 8: Metadata Generation
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 8: METADATA GENERATION")
        logger.info("=" * 80)
        audit.log_pipeline_event("metadata", "started", video_path)
        
        try:
            platforms = ["TikTok", "Instagram", "YouTube"]
            
            for clip in extracted_clips:
                # Generate captions
                captions = generate_captions(clip, platforms)
                clip['captions'] = captions
                
                # Generate hashtags
                hashtags = generate_hashtags(clip, platforms)
                clip['hashtags'] = hashtags
                
                logger.info(f"✓ Generated metadata for {clip['clip_id']}")
            
            audit.log_pipeline_event("metadata", "completed", video_path,
                                    {"clips_with_metadata": len(extracted_clips)})
        except Exception as e:
            logger.error(f"✗ Metadata generation failed: {str(e)}")
            audit.log_pipeline_event("metadata", "failed", video_path,
                                    error_message=str(e))
            raise
        
        # Stage 9: Scheduling
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 9: UPLOAD SCHEDULING")
        logger.info("=" * 80)
        audit.log_pipeline_event("scheduling", "started", video_path)
        
        try:
            queue = UploadQueue(config['rate_limits'])
            platforms = ["TikTok", "Instagram", "YouTube"]
            
            scheduled_tasks = queue.schedule_clips(extracted_clips, platforms)
            logger.info(f"✓ Scheduled {len(scheduled_tasks)} upload tasks")
            
            audit.log_pipeline_event("scheduling", "completed", video_path,
                                    {"scheduled_tasks": len(scheduled_tasks)})
        except Exception as e:
            logger.error(f"✗ Scheduling failed: {str(e)}")
            audit.log_pipeline_event("scheduling", "failed", video_path,
                                    error_message=str(e))
            raise
        
        # Stage 10: Platform Uploads
        logger.info("\n" + "=" * 80)
        logger.info("STAGE 10: PLATFORM UPLOADS")
        logger.info("=" * 80)
        audit.log_pipeline_event("uploads", "started", video_path)
        
        upload_credentials = {
            "TikTok": {},
            "Instagram": {},
            "YouTube": {}
        }
        
        successful_uploads = 0
        failed_uploads = 0
        
        for task in scheduled_tasks:
            clip = task['clip']
            platform = task['platform']
            clip_id = clip['clip_id']
            
            logger.info(f"\nUploading {clip_id} to {platform}...")
            
            # Check if upload is allowed (rate limiting)
            if not queue.can_upload(platform):
                logger.info(f"Rate limit reached for {platform}, skipping for now")
                audit.log_upload_event(clip_id, platform, "rate_limited")
                continue
            
            try:
                caption = clip['captions'].get(platform, "")
                hashtags = clip['hashtags'].get(platform, [])
                video_file = clip['file_path']
                
                upload_id = None
                
                if platform == "TikTok":
                    upload_id = upload_to_tiktok(
                        video_file, caption, hashtags, upload_credentials["TikTok"]
                    )
                elif platform == "Instagram":
                    upload_id = upload_to_instagram(
                        video_file, caption, hashtags, upload_credentials["Instagram"]
                    )
                elif platform == "YouTube":
                    upload_id = upload_to_youtube(
                        video_file, caption, hashtags, upload_credentials["YouTube"]
                    )
                
                if upload_id:
                    logger.info(f"✓ Upload successful: {upload_id}")
                    queue.record_upload(platform, clip_id, success=True)
                    audit.log_upload_event(clip_id, platform, "success", upload_id)
                    successful_uploads += 1
                else:
                    logger.warning(f"✗ Upload failed (no ID returned)")
                    queue.record_upload(platform, clip_id, success=False)
                    audit.log_upload_event(clip_id, platform, "failed")
                    failed_uploads += 1
                
            except Exception as e:
                logger.error(f"✗ Upload error: {str(e)}")
                queue.record_upload(platform, clip_id, success=False)
                audit.log_upload_event(clip_id, platform, "failed", error_message=str(e))
                failed_uploads += 1
        
        audit.log_pipeline_event("uploads", "completed", video_path,
                                {"successful": successful_uploads,
                                 "failed": failed_uploads})
        
        # Pipeline Summary
        logger.info("\n" + "=" * 80)
        logger.info("PIPELINE SUMMARY")
        logger.info("=" * 80)
        logger.info(f"Input video: {video_path}")
        logger.info(f"Clips generated: {len(extracted_clips)}")
        logger.info(f"Upload tasks scheduled: {len(scheduled_tasks)}")
        logger.info(f"Successful uploads: {successful_uploads}")
        logger.info(f"Failed uploads: {failed_uploads}")
        logger.info(f"Clips directory: {clips_dir}")
        logger.info(f"Audit database: {audit.db_path}")
        logger.info("=" * 80)
        
        audit.log_pipeline_event("pipeline", "completed", video_path,
                                {"clips": len(extracted_clips),
                                 "uploads": successful_uploads})
        
    except Exception as e:
        logger.error(f"\nPipeline failed: {str(e)}")
        audit.log_pipeline_event("pipeline", "failed", video_path,
                                error_message=str(e))
        raise


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Automated Short-Form Content Clipping & Distribution System'
    )
    parser.add_argument(
        'video_path',
        help='Path to input video file'
    )
    parser.add_argument(
        '-o', '--output',
        default='output',
        help='Output directory (default: output)'
    )
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        run_pipeline(args.video_path, args.output)
    except KeyboardInterrupt:
        logger.info("\nPipeline interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nFatal error: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()
